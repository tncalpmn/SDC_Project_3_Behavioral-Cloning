{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout, Lambda, Cropping2D\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "import sklearn\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global Parameters and Swithes\n",
    "flip = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flipping is not necessary\n"
     ]
    }
   ],
   "source": [
    "# Image Flipper\n",
    "imagePathRoot = \"./TrainingData\"\n",
    "allFileNames = [x for x in os.listdir(imagePathRoot) if  not x.startswith(\".\")]\n",
    "\n",
    "if flip:\n",
    "    for fileName in allFileNames:\n",
    "        print(\"Generating Flipped Images for\",fileName)\n",
    "        singleSamplePath = imagePathRoot +'/'+ fileName\n",
    "        flippedImagePath = singleSamplePath + '/Flipped_IMG'\n",
    "\n",
    "        if not os.path.exists(flippedImagePath):\n",
    "            os.makedirs(flippedImagePath)\n",
    "\n",
    "        imagePath = singleSamplePath + '/IMG'\n",
    "\n",
    "        allImageNames = os.listdir(imagePath)\n",
    "        for imgName in allImageNames:\n",
    "            image = Image.open(imagePath + '/' + imgName)\n",
    "            flipImage = image.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "            flipImage.save(flippedImagePath+'/'+imgName.replace('.jpg','')+'_flipped.jpg', \"JPEG\")\n",
    "\n",
    "    print(\"Images are flipped and saved successfully..\")\n",
    "else:\n",
    "    print(\"Flipping is not necessary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Log Data Flipper\n",
    "if flip:\n",
    "    for fileName in allFileNames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Image Reader - Random Examples from each Sample\n",
    "\n",
    "\n",
    "imageDim = '''TODO-(depth,height,width)''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show how much of the Image has to be cropped\n",
    "top = '''TODO-integer'''\n",
    "bottom = '''TODO-integer'''\n",
    "left = '''TODO-integer'''\n",
    "right = '''TODO-integer'''\n",
    "\n",
    "croppedImageDim = (imageDim[0],imageDim[1]-(top+bottom),imageDim[2]-(left+right))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NVIDIA Architecture + My improvements\n",
    "\n",
    "def myNet(train_Gen, validation_Gen, numOfTrainSample, numOfValSample, ep):\n",
    "\n",
    "    #Create the Keras Model\n",
    "    model = Sequential()\n",
    "\n",
    "    #Crop Images \n",
    "    model.add(Cropping2D(cropping=((top,bottom),(left,right)),input_shape=imageDim))\n",
    "\n",
    "    #Normalization and Mean center\n",
    "    model.add(Lambda(lambda x: (x/255.0)-0.5)) # TODO maybe also output_shape=croppedImageDim OR No size Paramenters at all?\n",
    "\n",
    "    #Convolutional Layer 1\n",
    "    model.add(Convolution2D(24,5,5))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Convolutional Layer 2\n",
    "    model.add(Convolution2D(36,5,5))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Convolutional Layer 3\n",
    "    model.add(Convolution2D(48,5,5))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Convolutional Layer 4\n",
    "    model.add(Convolution2D(64,3,3))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Convolutional Layer 5\n",
    "    model.add(Convolution2D(64,3,3))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Flatten\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Fully Connected Layer 1\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Fully Connected Layer 2\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dropout(0.5)) #TODO ?\n",
    "\n",
    "    #Fully Connected Layer 3\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Final Output\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mse',optimizer='adam')\n",
    "    historyObj = model.fit_generator(X_Train_Gen, samples_per_epoch=numOfTrainSample,\n",
    "                        validation_data=validation_Gen, nb_val_samples=numOfValSample\n",
    "                        nb_epoch = ep, verbose=1)\n",
    "\n",
    "    return historyObj # Can be used for Visualing historyObj.history['loss'] and historyObj.history['loss'] && also check out Keys: print(history_object.history.keys())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
