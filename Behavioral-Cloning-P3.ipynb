{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tunc/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout, Lambda, Cropping2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "import sklearn\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global Parameters and Swithes\n",
    "flip = False\n",
    "cropSave = False\n",
    "limitDataSample = True # Not forget to swith off during real training\n",
    "limitImages = 10\n",
    "flipSuffixForImage = '_flipped.jpg'\n",
    "flipSuffixForCSV = '_flipped.csv'\n",
    "imagePathRoot = \"./TrainingData\"\n",
    "croppedImagePathRoot = \"./Cropped_Images\"\n",
    "allFileNames = [x for x in os.listdir(imagePathRoot) if  not x.startswith(\".\")] # Sample_1, Sample_2, Sample_3...\n",
    "batch_size=32\n",
    "ep = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image flipping is not necessary anymore\n"
     ]
    }
   ],
   "source": [
    "# Image Flipper\n",
    "if flip:\n",
    "    for fileName in allFileNames:\n",
    "        print(\"Generating Flipped Images for\",fileName)\n",
    "        singleSamplePath = imagePathRoot +'/'+ fileName\n",
    "        flippedImagePath = singleSamplePath + '/Flipped_IMG'\n",
    "\n",
    "        if not os.path.exists(flippedImagePath):\n",
    "            os.makedirs(flippedImagePath)\n",
    "\n",
    "        imagePath = singleSamplePath + '/IMG'\n",
    "\n",
    "        allImageNames = os.listdir(imagePath)\n",
    "        for imgName in allImageNames:\n",
    "            image = Image.open(imagePath + '/' + imgName)\n",
    "            flipImage = image.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "            flipImage.save(flippedImagePath+'/'+imgName.replace('.jpg','')+flipSuffixForImage, \"JPEG\")\n",
    "\n",
    "    print(\"Images are flipped and saved successfully..\")\n",
    "else:\n",
    "    print(\"Image flipping is not necessary anymore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Csv Flipping is not necessary anymore\n"
     ]
    }
   ],
   "source": [
    "#Log Data Flipper\n",
    "allSamples = []\n",
    "for fileName in allFileNames:\n",
    "    singleDrivingLogPath = imagePathRoot +'/'+ fileName +'/'+ \"driving_log.csv\"\n",
    "    allLinesFlipped = []\n",
    "    originalWithOutPaths = []\n",
    "    with open(singleDrivingLogPath) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            orgLine = line.copy()\n",
    "            for i in range(0,3): # First three columns are document names and suffix has to be added\n",
    "                #root = '/'.join(str(path) for path in line[i].split(\"/\")[:-1])\n",
    "                line[i] = line[i].split(\"/\")[-1].split(\".\")[0] + flipSuffixForImage\n",
    "                orgLine[i] = orgLine[i].split(\"/\")[-1].split(\".\")[0] + \".jpg\" \n",
    "            steeringAng = line[3] #Â Here steering is multiplied by -1\n",
    "            line[3] = str(-1 * float(steeringAng))\n",
    "            allLinesFlipped.append(line)\n",
    "            originalWithOutPaths.append(orgLine)\n",
    "    allSamples = allSamples + (allLinesFlipped + originalWithOutPaths)\n",
    "    if flip:\n",
    "        with open(imagePathRoot +'/'+ fileName +'/'+ \"driving_log\" + flipSuffixForCSV, \"w\") as csv_file:\n",
    "            writer = csv.writer(csv_file,delimiter=',')\n",
    "            for line in allLinesFlipped:\n",
    "                writer.writerow(line)\n",
    "        with open(imagePathRoot +'/'+ fileName +'/'+ \"driving_log\" + \"_without_path.csv\", \"w\") as csv_file:\n",
    "            writer = csv.writer(csv_file,delimiter=',')\n",
    "            for line in originalWithOutPaths:\n",
    "                writer.writerow(line)                \n",
    "if flip:    \n",
    "    print(\"Csv Files are flipped and saved successfully..\")\n",
    "else:\n",
    "    print(\"Csv Flipping is not necessary anymore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Visualser\n",
    "#Crop Degrees from:\n",
    "top = 64\n",
    "bottom = 22\n",
    "left = 0\n",
    "right = 0\n",
    "\n",
    "images = []\n",
    "for fileName in allFileNames:\n",
    "    singleSamplePath = imagePathRoot +'/'+ fileName\n",
    "    imagePath = singleSamplePath + '/IMG'\n",
    "    allImageNames = os.listdir(imagePath)\n",
    "    image = Image.open(imagePath + '/' + allImageNames[0]) # Take first picture from all Samples\n",
    "    arrIm = np.array(image)\n",
    "    images.append(arrIm)\n",
    "    #Crop Image and add after for visualization\n",
    "    image = image.crop((left, top, arrIm.shape[1]-right, arrIm.shape[0]-bottom)) #(left, top, right, bottom )\n",
    "    images.append(np.array(image))\n",
    "\n",
    "%matplotlib inline\n",
    "fig=plt.figure(figsize=(images[0].shape[0], images[0].shape[1]))\n",
    "for i in range(1,len(images)+1):\n",
    "    fig.add_subplot(len(images), 2, i)\n",
    "    img = images[i-1]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Cropper\n",
    "if cropSave:\n",
    "    for fileName in allFileNames:\n",
    "        print(fileName)\n",
    "        singleSamplePath = imagePathRoot +'/'+ fileName\n",
    "        folderList = ['/IMG','/Flipped_IMG']\n",
    "        for eachFolder in folderList:\n",
    "            imagePath = singleSamplePath + eachFolder\n",
    "            allImageNames = os.listdir(imagePath)\n",
    "            for imgName in allImageNames:\n",
    "                image = Image.open(imagePath + '/' + imgName) # Take first picture from all Samples\n",
    "                image = image.crop((left, top, arrIm.shape[1]-right, arrIm.shape[0]-bottom)) #(left, top, right, bottom )\n",
    "                image.save('./Cropped_Images/'+ imgName)\n",
    "    print(\"Cropping Finished\")\n",
    "else:\n",
    "    print(\"Cropping is not necessary anymore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDim = images[0].shape # Even index Original \n",
    "orgDepth = imageDim[2]\n",
    "orgHeight = imageDim[0]\n",
    "orgWidth = imageDim[1]\n",
    "print(\"Original Image Dimensions\",imageDim)\n",
    "\n",
    "croppedImageDim = images[1].shape # Odd index Cropped \n",
    "cropDepth = croppedImageDim[2]\n",
    "cropHeight = croppedImageDim[0]\n",
    "cropWidth = croppedImageDim[1]\n",
    "print(\"Cropped Image Dimensions\",croppedImageDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Image:  # Not Used  \n",
    "    def __init__(self, name, adress,steering):\n",
    "        self.name = name\n",
    "        self.adress = adress\n",
    "        self.steering = steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sake of Debugging limit the datasample\n",
    "if limitDataSample:\n",
    "    allSamples = allSamples[:limitImages]\n",
    "print(\"Amount of picture from each view: left, center, right:\",len(allSamples)) # All Image Information can be found allSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Split\n",
    "allSamplesFilt = [allSamples[i][0:4] for i in range(len(allSamples))] # Get Rid of Unused Features\n",
    "train_samples, validation_samples = train_test_split(allSamplesFilt, test_size=0.2) # Image Information (left,center,right,) of one frame\n",
    "num_train_sample = len(train_samples)\n",
    "num_validation_sample = len(validation_samples)\n",
    "\n",
    "\n",
    "print(\"Number of 'Center' Training Images: \", num_train_sample) # (center,left,right,steering)\n",
    "print(\"Number of 'Center' Validation Images: \", num_validation_sample)\n",
    "print(\"Each Sample Indexing -> train_samples[Index]:\")\n",
    "i = 0\n",
    "for element in train_samples[0]:\n",
    "    print(\"    Index {} : {}\".format(i,element))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVIDIA Architecture + My improvements\n",
    "def myNet(input_shape):\n",
    "\n",
    "    #Create the Keras Model\n",
    "    model = Sequential()\n",
    "\n",
    "    #Crop Images \n",
    "    #model.add(Cropping2D(cropping=((top,bottom),(left,right)),input_shape=(orgDepth, orgHeight, orgWidth))) # Original Dimension (depth,height,width)\n",
    "\n",
    "    #Normalization and Mean center\n",
    "    model.add(Lambda(lambda x: (x/255.0)-0.5, input_shape = input_shape))\n",
    "\n",
    "    #Convolutional Layer 1\n",
    "    model.add(Convolution2D(24,(5,5)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Convolutional Layer 2\n",
    "    model.add(Convolution2D(36,(5,5)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Convolutional Layer 3\n",
    "    model.add(Convolution2D(48,(5,5)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Convolutional Layer 4\n",
    "    model.add(Convolution2D(64,(3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Convolutional Layer 5\n",
    "    model.add(Convolution2D(64,(3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Flatten\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Fully Connected Layer 1\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Fully Connected Layer 2\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dropout(0.5)) #TODO ? MAX Pooling?\n",
    "\n",
    "    #Fully Connected Layer 3\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Final Output\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model # Can be used for Visualing historyObj.history['loss'] and historyObj.history['loss'] && also check out Keys: print(history_object.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GENERATOR Function - Keras will use\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = croppedImagePathRoot + \"/\" + batch_sample[0] # 0 index is Center Image\n",
    "                center_image = cv2.imread(name)\n",
    "                center_angle = float(batch_sample[3]) # 3 index is Steering\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation and Training Seperation\n",
    "#input_shape = (cropDepth, cropHeight, cropWidth) # Initial Input Image\n",
    "input_shape = (cropHeight,cropWidth,cropDepth) # Initial Input Image\n",
    "\n",
    "print(input_shape)\n",
    "model = myNet(input_shape)\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "historyObj = model.fit_generator(train_generator, steps_per_epoch=num_train_sample,\n",
    "                        validation_data=validation_generator, steps=num_validation_sample ,\n",
    "                        epochs = ep, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(historyObj.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(historyObj.history['loss'])\n",
    "plt.plot(historyObj.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''TODOs \n",
    "1) Left And Right Image Usage\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
